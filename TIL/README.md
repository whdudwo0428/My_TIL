## 비전 AI 주요 알고리즘 및 모델

### 1. Classification (분류)
- **정의**: 이미지 내 특정 객체의 카테고리를 식별하고 분류. 
  - 예: "이 이미지는 95% 확률로 코끼리를 포함하고 있다."
- **주요 모델**: 
  - **AlexNet**: 딥러닝 기반 이미지 분류의 초기 모델로, 이미지넷 챌린지 우승을 통해 큰 영향을 끼침.
  - **VGGNet**: 네트워크의 깊이를 늘려 분류 정확도를 크게 향상. 계층 구조를 깊게 쌓아 높은 성능을 보여줌.

### 2. Detection (객체 탐지)
#### 정의
- 이미지 내 객체의 위치를 **바운딩 박스(Bounding Box)**로 탐지하고, 각 박스에 **객체 정보(클래스 및 점수)**를 부여.
- 픽셀 단위의 세그멘테이션 없이, 대략적인 객체의 영역과 위치를 빠르게 탐지.
  - 예: "축구 경기 이미지에서 선수, 공, 심판의 위치를 탐지하고, 해당 객체를 분류."

#### 효율성의 이유
- 실시간 데이터 처리에 적합하며, 자율주행, 스포츠 분석, 감시 시스템 등에서 널리 사용.
- 계산 자원 소모가 적어, 제한된 하드웨어에서도 높은 성능 발휘 가능.
- 객체의 위치와 클래스 정보를 동시에 제공하므로 빠르고 간단한 처리에 유리.

#### 주요 모델
1. **YOLO (You Only Look Once)**
   - **작동 방식**: 
     - 입력 이미지를 단일 신경망으로 처리하여, 각 그리드 셀에서 클래스 확률과 위치(Bounding Box)를 예측.
     - 실시간 처리(30FPS 이상)가 가능하며, 단일 단계로 객체 탐지 수행.
   - **장점**: 
     - 빠른 속도: 단일 패스(single pass)로 클래스와 위치를 예측.
     - 효율성: 경량화된 구조로 실시간 분석에 적합.
   - **단점**: 
     - 작은 객체 탐지에서 정확도 부족.
     - 복잡한 배경에서는 정밀도가 다소 낮아질 수 있음.
   - **예시**: 
     - 축구 경기 중 선수와 공, 심판의 위치를 빠르게 탐지하여 공격 상황 분석.
2. **Faster R-CNN (Region-Based Convolutional Neural Network)**
   - **작동 방식**: 
     - **영역 제안 네트워크(Region Proposal Network, RPN)**를 통해 유망한 객체 위치를 먼저 제안.
     - 이후, 해당 영역에서 객체의 클래스와 바운딩 박스를 정밀하게 예측.
   - **장점**: 
     - 높은 정밀도: 객체의 위치와 클래스를 정확히 탐지.
     - 복잡한 환경에서도 강력한 성능 발휘.
   - **단점**: 
     - YOLO에 비해 속도는 느림.
     - 하드웨어 자원 요구량이 상대적으로 큼.
   - **예시**: 
     - 경기 중 공의 궤적, 선수 간 거리, 심판 위치를 정밀 분석.

#### YOLO vs. Faster R-CNN 비교
| 모델          | 속도             | 정밀도           | 적용 사례                           |
|---------------|------------------|------------------|------------------------------------|
| YOLO          | 빠름 (30 FPS 이상) | 상대적으로 낮음   | 실시간 객체 탐지: 공격 상황 추적     |
| Faster R-CNN  | 느림             | 높음             | 정밀 분석: 선수 간 거리, 패스 분석  |

### 3. Segmentation (분할)
- **정의**: 픽셀 단위로 이미지 내 객체를 구분. 
  - **Semantic Segmentation**: 동일 클래스를 가진 객체를 하나의 그룹으로 처리.
    - 예: 이미지의 모든 코끼리를 한 그룹으로 표시.
  - **Instance Segmentation**: 동일한 클래스에 속하더라도 객체를 개별적으로 구분.
    - 예: 3마리의 코끼리를 각각 다른 그룹으로 분류.

#### 주요 모델
1. **FCN (Fully Convolutional Networks)**
   - **작동 원리**:
     - 기존 CNN의 Fully Connected Layer를 제거하고, 컨볼루셔널 레이어만을 사용하여 이미지의 위치 정보(Spatial Information)를 유지.
     - 입력 이미지를 **다운샘플링(특징 추출)**하고, **업샘플링(Deconvolution)**으로 복원하여 원본 이미지 크기와 동일한 해상도로 출력.
   - **장점**:
     - 효율적이고 다양한 해상도의 데이터 처리 가능.
     - 자율주행에서 도로와 차선과 같은 넓은 영역의 객체 분리에 적합.
   - **한계**:
     - 업샘플링 과정에서 경계 정보 손실 발생.
     - 작은 객체나 복잡한 경계의 정확도 부족.
2. **U-Net**
   - **작동 원리**:
     - 인코더-디코더 구조로 다운샘플링과 업샘플링 과정에서 정보를 전달.
     - 스킵 커넥션(Skip Connections)을 사용하여 세밀한 경계를 복원.
   - **특징**:
     - 소규모 데이터셋에서도 강력한 성능 발휘.
     - 의료 영상 및 결함 탐지와 같은 정밀한 작업에 적합.
   - **장점**:
     - 세밀한 경계 복원 및 작은 객체 처리 가능.
   - **한계**:
     - 연산량이 많아 실시간 작업에 비효율적.
   - **예시**:
     - 의료 영상에서 세포핵과 같은 작은 영역 분리.
3. **DeepLab**
   - **작동 원리**:
     - 다이얼레이티드 컨볼루션(Dilated Convolution)을 사용하여 더 넓은 컨텍스트 학습.
     - 픽셀 단위의 정밀도를 높이기 위해 CRF(Conditional Random Field) 적용.
   - **특징**:
     - 복잡한 장면에서 객체를 픽셀 단위로 정밀하게 구분.
   - **장점**:
     - 높은 정밀도와 복잡한 객체 구분에 적합.
     - 자율주행, 도시 환경 분석에서 강력한 성능 발휘.
   - **한계**:
     - 연산량이 많아 실시간 처리에는 부적합.