# 자율주행 개요

## 자율주행이란 무엇인가?
자율주행의 핵심은 주변 환경을 인식하고 데이터를 기반으로 차량을 제어하는 것입니다.

### 1-1. 자율주행 단계 (SAE 0~5 레벨)

#### 1) 자율주행 단계 소개
- 자율주행은 미국 자동차학회(SAE)에서 **6단계(Level 0~5)**로 나뉩니다.
- 단계별로 자율화 수준과 운전자 개입 정도가 구분됩니다.

#### 2) 자율주행 단계 상세 설명
- **Level 0: 비자동화 (Manual Driving)**
  - 자율주행 기능 없음.
  - 운전자가 모든 차량 제어를 담당.
  - 차량은 옆 차량 알림 등의 보조 정보만 제공.
- **Level 1: 운전자 지원 (Driver Assistance)**
  - 단일 기능 지원.
  - 차선 유지 보조나 크루즈 컨트롤과 같은 시스템 포함.
  - 운전자가 차량의 대부분 제어.
- **Level 2: 부분 자동화 (Partial Automation)**
  - 차량이 가속, 감속, 조향 기능을 모두 수행 가능.
  - 예: 차량이 스스로 급브레이크를 밟는 기능.
  - 운전자는 항상 주행 상황을 모니터링해야 함.
- **Level 3: 조건부 자동화 (Conditional Automation)**
  - 특정 조건(예: 고속도로)에서 차량이 스스로 주행.
  - 운전자는 돌발 상황에만 개입.
  - 국내외 기업들이 상용화 단계에 진입 중.
- **Level 4: 고도 자동화 (High Automation)**
  - 대부분의 도로 환경에서 차량이 스스로 주행 가능.
  - 운전자 개입 필요 없음.
  - 돌발 상황이 많아 법적 책임 및 사고 대처 논란 존재.
- **Level 5: 완전 자율주행 (Full Automation)**
  - 모든 환경에서 운전자가 개입하지 않아도 주행 가능.
  - 차량이 전적으로 주행을 제어하며, 운전석이 필요하지 않음.

### 3) 현재 기술과 기업 동향
- **Level 3~4 단계**가 대부분의 기업들의 상용화 목표.
- 현재 자율주행 기술은 특정 조건에서의 안정성을 보완하는 방향으로 발전 중.

### 4) 자율주행 기술의 과제
- **환경 변수 극복**
  - 비, 눈, 조명 조건에서 카메라 왜곡이나 학습 데이터 부족으로 인한 오류.
- **센서 퓨전 기술의 발전**
  - 다양한 센서 데이터를 융합해 신뢰도를 높이고, 3D 맵을 기반으로 의사결정 지원.
- **돌발 상황 대응 연구**
  - 기업 및 연구소에서 비상 상황 대처 기술 개발 중.

---

# 자율주행에서의 시각 정보 수집

## 2-1. 주요 센서 종류

자율주행 차량은 **레이더**, **라이다(LiDAR)**, 그리고 **카메라**라는 세 가지 주요 장치로 시각 정보를 수집합니다. 각 센서는 고유의 장단점을 가지고 있으며, 자율주행에서 중요한 역할을 담당합니다.

### 1) 레이더 (Radar)
- **원리**: 전자파(라디오파, 마이크로파)를 발사해 반사 신호를 수신하여 거리, 속도, 방향 정보를 계산.
- **장점**:
  - 날씨와 시간 등의 환경 변수에 강함.
  - 신뢰도가 높아 다양한 조건에서 안정적.
  - 상대적으로 저렴한 비용.
- **단점**:
  - 물체의 형상을 정확히 인식하기 어려움.

### 2) 라이다 (LiDAR)
- **원리**: 레이저 펄스를 발사하고 대상에서 반사된 신호의 시간을 측정하여 거리 및 3차원 데이터를 생성.
- **장점**:
  - 높은 정확도와 정밀한 3D 형상 데이터를 제공.
  - 대상의 폭, 거리, 높낮이를 반영한 고해상도 3D 공간 정보 획득 가능.
  - 오차 범위가 센티미터 단위로 매우 작음.
- **단점**:
  - 고비용.
  - 환경 변수(날씨, 조명 등)에 민감.
  - 대량 데이터 처리 및 노이즈 간섭 문제 존재.

### 3) 카메라
- **원리**: RGB 영상 기반으로 물체를 시각적으로 인식.
- **장점**:
  - 비용이 저렴하고, 풍부한 시각적 정보를 제공.
  - 텍스처와 색상 등 추가적인 시각적 세부사항 인식 가능.
- **단점**:
  - 날씨, 조명 변화 등 환경 변수에 민감.
  - 원근 측정에 한계가 있음.

## 2-2. 센서 비교 및 활용

| 센서   | 형상 인식 정도 | 외부 환경 영향 | 비용 |
|--------|----------------|----------------|------|
| 레이더 | 낮음           | 낮음           | 저가 |
| 라이다 | 높음           | 높음           | 고가 |
| 카메라 | 중간           | 높음           | 저가 |

### 특징 및 활용
- **레이더**:
  - 형상 인식은 제한적이나, 날씨와 시간 같은 환경 변수에 강하며, 비용이 저렴.
  - 현재 보편적으로 사용되며, 고신뢰도를 제공함.
- **라이다**:
  - 높은 정밀도와 정확도를 제공하며, 3D 공간 데이터를 상세히 수집.
  - 고가이며, 환경 변수(비, 안개 등)에 민감.
- **카메라**:
  - 시각적 정보(색상, 텍스처, 물체 식별)를 통해 차선, 도로 표지판, 장애물 등을 인식.
  - End-to-End 학습: 카메라 데이터를 신경망에 직접 전달하여 차량 제어를 학습 및 판단.

---

# 비전 AI 주요 알고리즘 및 모델

## 3-1. Classification (분류)
- **정의**: 이미지 내 특정 객체의 카테고리를 식별하고 분류.
  - 예: "이 이미지는 95% 확률로 코끼리를 포함하고 있다."
- **주요 모델**:
  - **AlexNet**: 딥러닝 기반 이미지 분류의 초기 모델로, 이미지넷 챌린지 우승을 통해 큰 영향을 끼침.
  - **VGGNet**: 네트워크의 깊이를 늘려 분류 정확도를 크게 향상.

## 3-2. Detection (객체 탐지)
- **정의**:
  - 이미지 내 객체의 위치를 **바운딩 박스(Bounding Box)**로 탐지하고, 각 박스에 **객체 정보(클래스 및 점수)**를 부여.
- **효율성의 이유**:
  - 실시간 데이터 처리에 적합하며, 자율주행, 스포츠 분석, 감시 시스템 등에서 널리 사용.
