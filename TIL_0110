# 자율주행 개요

## 자율주행이란 무엇인가?
자율주행의 핵심은 주변 환경을 인식하고 데이터를 기반으로 차량을 제어하는 것입니다.

### 1-1. 자율주행 단계 (SAE 0~5 레벨)

#### 1) 자율주행 단계 소개
- 자율주행은 미국 자동차학회(SAE)에서 **6단계(Level 0~5)**로 나뉩니다.
- 단계별로 자율화 수준과 운전자 개입 정도가 구분됩니다.

#### 2) 자율주행 단계 상세 설명
- **Level 0: 비자동화 (Manual Driving)**
  - 자율주행 기능 없음.
  - 운전자가 모든 차량 제어를 담당.
  - 차량은 옆 차량 알림 등의 보조 정보만 제공.
- **Level 1: 운전자 지원 (Driver Assistance)**
  - 단일 기능 지원.
  - 차선 유지 보조나 크루즈 컨트롤과 같은 시스템 포함.
  - 운전자가 차량의 대부분 제어.
- **Level 2: 부분 자동화 (Partial Automation)**
  - 차량이 가속, 감속, 조향 기능을 모두 수행 가능.
  - 예: 차량이 스스로 급브레이크를 밟는 기능.
  - 운전자는 항상 주행 상황을 모니터링해야 함.
- **Level 3: 조건부 자동화 (Conditional Automation)**
  - 특정 조건(예: 고속도로)에서 차량이 스스로 주행.
  - 운전자는 돌발 상황에만 개입.
  - 국내외 기업들이 상용화 단계에 진입 중.
- **Level 4: 고도 자동화 (High Automation)**
  - 대부분의 도로 환경에서 차량이 스스로 주행 가능.
  - 운전자 개입 필요 없음.
  - 돌발 상황이 많아 법적 책임 및 사고 대처 논란 존재.
- **Level 5: 완전 자율주행 (Full Automation)**
  - 모든 환경에서 운전자가 개입하지 않아도 주행 가능.
  - 차량이 전적으로 주행을 제어하며, 운전석이 필요하지 않음.

### 3) 현재 기술과 기업 동향
- **Level 3~4 단계**가 대부분의 기업들의 상용화 목표.
- 현재 자율주행 기술은 특정 조건에서의 안정성을 보완하는 방향으로 발전 중.

### 4) 자율주행 기술의 과제
- **환경 변수 극복**
  - 비, 눈, 조명 조건에서 카메라 왜곡이나 학습 데이터 부족으로 인한 오류.
- **센서 퓨전 기술의 발전**
  - 다양한 센서 데이터를 융합해 신뢰도를 높이고, 3D 맵을 기반으로 의사결정 지원.
- **돌발 상황 대응 연구**
  - 기업 및 연구소에서 비상 상황 대처 기술 개발 중.

---

# 자율주행에서의 시각 정보 수집

## 2-1. 주요 센서 종류

자율주행 차량은 **레이더**, **라이다(LiDAR)**, 그리고 **카메라**라는 세 가지 주요 장치로 시각 정보를 수집합니다. 각 센서는 고유의 장단점을 가지고 있으며, 자율주행에서 중요한 역할을 담당합니다.

### 1) 레이더 (Radar)
- **원리**: 전자파(라디오파, 마이크로파)를 발사해 반사 신호를 수신하여 거리, 속도, 방향 정보를 계산.
- **장점**:
  - 날씨와 시간 등의 환경 변수에 강함.
  - 신뢰도가 높아 다양한 조건에서 안정적.
  - 상대적으로 저렴한 비용.
- **단점**:
  - 물체의 형상을 정확히 인식하기 어려움.

### 2) 라이다 (LiDAR)
- **원리**: 레이저 펄스를 발사하고 대상에서 반사된 신호의 시간을 측정하여 거리 및 3차원 데이터를 생성.
- **장점**:
  - 높은 정확도와 정밀한 3D 형상 데이터를 제공.
  - 대상의 폭, 거리, 높낮이를 반영한 고해상도 3D 공간 정보 획득 가능.
  - 오차 범위가 센티미터 단위로 매우 작음.
- **단점**:
  - 고비용.
  - 환경 변수(날씨, 조명 등)에 민감.
  - 대량 데이터 처리 및 노이즈 간섭 문제 존재.

### 3) 카메라
- **원리**: RGB 영상 기반으로 물체를 시각적으로 인식.
- **장점**:
  - 비용이 저렴하고, 풍부한 시각적 정보를 제공.
  - 텍스처와 색상 등 추가적인 시각적 세부사항 인식 가능.
- **단점**:
  - 날씨, 조명 변화 등 환경 변수에 민감.
  - 원근 측정에 한계가 있음.

## 2-2. 센서 비교 및 활용

| 센서   | 형상 인식 정도 | 외부 환경 영향 | 비용 |
|--------|----------------|----------------|------|
| 레이더 | 낮음           | 낮음           | 저가 |
| 라이다 | 높음           | 높음           | 고가 |
| 카메라 | 중간           | 높음           | 저가 |

### 특징 및 활용
- **레이더**:
  - 형상 인식은 제한적이나, 날씨와 시간 같은 환경 변수에 강하며, 비용이 저렴.
  - 현재 보편적으로 사용되며, 고신뢰도를 제공함.
- **라이다**:
  - 높은 정밀도와 정확도를 제공하며, 3D 공간 데이터를 상세히 수집.
  - 고가이며, 환경 변수(비, 안개 등)에 민감.
- **카메라**:
  - 시각적 정보(색상, 텍스처, 물체 식별)를 통해 차선, 도로 표지판, 장애물 등을 인식.
  - End-to-End 학습: 카메라 데이터를 신경망에 직접 전달하여 차량 제어를 학습 및 판단.

---

# 비전 AI 주요 알고리즘 및 모델

## 3-1. Classification (분류)
- **정의**: 이미지 내 특정 객체의 카테고리를 식별하고 분류.
  - 예: "이 이미지는 95% 확률로 코끼리를 포함하고 있다."
- **주요 모델**:
  - **AlexNet**: 딥러닝 기반 이미지 분류의 초기 모델로, 이미지넷 챌린지 우승을 통해 큰 영향을 끼침.
  - **VGGNet**: 네트워크의 깊이를 늘려 분류 정확도를 크게 향상.

## 3-2 Detection (객체 탐지)
- 정의 : 이미지 내 객체의 위치를 **바운딩 박스(Bounding Box)**로 탐지하고, 각 박스에 **객체 정보(클래스 및 점수)**를 부여합니다. 픽셀 단위의 세그멘테이션 없이, 대략적인 객체의 영역과 위치를 빠르게 탐지합니다.
  - 예: "축구 경기 이미지에서 선수, 공, 심판의 위치를 탐지하고, 해당 객체를 분류."

### 효율성의 이유
- 실시간 데이터 처리에 적합하며, 자율주행, 스포츠 분석, 감시 시스템 등에서 널리 사용됩니다.
- 계산 자원 소모가 적어, 제한된 하드웨어에서도 높은 성능을 발휘할 수 있습니다.
- 객체의 위치와 클래스 정보를 동시에 제공하므로 빠르고 간단한 처리에 유리합니다.

### 주요 모델
#### YOLO (You Only Look Once)
- **작동 방식**: 입력 이미지를 단일 신경망으로 처리하여, 각 그리드 셀에서 클래스 확률과 위치(Bounding Box)를 예측합니다. 실시간 처리(30FPS 이상)가 가능하며, 단일 단계로 객체 탐지를 수행합니다.
- **장점**:
  - 빠른 속도: 단일 패스(single pass)로 클래스와 위치를 예측.
  - 효율성: 경량화된 구조로 실시간 분석에 적합.
- **단점**:
  - 작은 객체 탐지에서 정확도가 부족.
  - 복잡한 배경에서는 정밀도가 다소 낮아질 수 있음.
- **축구 경기 예시**:
  - 필드에서 선수 위치, 축구공 위치, 심판의 위치를 빠르게 탐지.
  - 공격 상황에서 상대 팀 선수 밀집도를 실시간으로 분석.

#### Faster R-CNN (Region-Based Convolutional Neural Network)
- **작동 방식**: **영역 제안 네트워크(Region Proposal Network, RPN)**를 통해 유망한 객체 위치를 먼저 제안하고, 해당 영역에서 객체의 클래스와 바운딩 박스를 정밀하게 예측합니다.
- **장점**:
  - 정밀도: 객체의 위치와 클래스를 정확히 탐지.
  - 복잡한 환경에서도 강력한 성능 발휘.
- **단점**:
  - YOLO에 비해 속도가 느림.
  - 하드웨어 자원 요구량이 상대적으로 큼.
- **축구 경기 예시**:
  - 경기 상황에서 공이 빠르게 이동하는 궤적을 정확히 추적.
  - 경기장에서의 선수 간 거리, 심판 위치 및 특정 지역 내 밀집도 분석.

### 축구 경기 객체 탐지 시 고려 사항
1. **다양한 객체 크기**:
   - 공, 선수, 심판의 크기 차이가 크므로 멀티스케일 학습이 필요합니다.
   - 작은 크기의 공 탐지를 위해 FPN(Feature Pyramid Network) 구조를 활용할 수 있습니다.
2. **속도 vs. 정확도**:
   - 실시간 중계나 분석에서는 YOLO와 같은 빠른 알고리즘이 적합합니다.
   - 경기 후 정밀 분석에는 Faster R-CNN이 더 유리합니다.
3. **객체 간 상호작용**:
   - 선수의 행동(패스, 슛 등)과 같은 시간적 상관성을 위해 Recurrent Neural Network(RNN) 기반의 Temporal Tracking을 추가할 수 있습니다.
